{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "indicatorsDf = pd.read_excel('StateIndicatorsDatabase_2024.xlsx', sheet_name='Data')\n",
    "\n",
    "x_cols = ['necm_fundinggap_q1', 'necm_fundinggap_q2', 'necm_fundinggap_q3', 'necm_fundinggap_q4', 'necm_fundinggap_q5']\n",
    "y_cols = ['necm_outcomegap_q1', 'necm_outcomegap_q2', 'necm_outcomegap_q3', 'necm_outcomegap_q4', 'necm_outcomegap_q5']\n",
    "\n",
    "df = indicatorsDf[x_cols + y_cols]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[x_cols]\n",
    "y = df[y_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "class Model:\n",
    "  def __init__(self, input_dims, output_dims):\n",
    "    self.model = Network(input_dims, output_dims)\n",
    "\n",
    "  def train(self, xtrain, ytrain, xval, yval):\n",
    "    loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "    optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "    n_epochs = 400\n",
    "    batch_size = 15\n",
    "    batch_start = torch.arange(0, len(xtrain), batch_size)\n",
    "\n",
    "    best_loss = np.inf\n",
    "    best_weights = None\n",
    "\n",
    "    print(f\"Training with {n_epochs} epochs and a batch size of {batch_size}\")\n",
    "\n",
    "    sample_times = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "      self.model.train()\n",
    "\n",
    "      for start in batch_start:\n",
    "          # take a batch\n",
    "          X_batch = xtrain[start:start+batch_size]\n",
    "          y_batch = ytrain[start:start+batch_size]\n",
    "\n",
    "          start_time = time.time()\n",
    "\n",
    "          # forward pass\n",
    "          outputs = self.model(X_batch)\n",
    "          loss = loss_fn(outputs, y_batch)\n",
    "          # backward pass\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          # update weights\n",
    "          optimizer.step()\n",
    "\n",
    "          end_time = time.time()\n",
    "          sample_times.append((end_time - start_time) / batch_size)\n",
    "\n",
    "      self.model.eval()\n",
    "      outputs = self.model(xval)\n",
    "      loss = loss_fn(outputs, yval)\n",
    "      if loss < best_loss:\n",
    "          best_loss = loss\n",
    "          best_weights = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "      if (epoch+1) % 10 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}, Best Loss: {:.4f}'.format(epoch+1, n_epochs, loss, best_loss))\n",
    "\n",
    "    print(f\"Average Sample Training Time: {np.mean(sample_times)} seconds\")\n",
    "    self.model.load_state_dict(best_weights)\n",
    "\n",
    "  def predict(self, value):\n",
    "    return self.model(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 400 epochs and a batch size of 15\n",
      "Epoch [10/400], Loss: 0.0272, Best Loss: 0.0272\n",
      "Epoch [20/400], Loss: 0.0211, Best Loss: 0.0211\n",
      "Epoch [30/400], Loss: 0.0189, Best Loss: 0.0186\n",
      "Epoch [40/400], Loss: 0.0174, Best Loss: 0.0174\n",
      "Epoch [50/400], Loss: 0.0170, Best Loss: 0.0168\n",
      "Epoch [60/400], Loss: 0.0165, Best Loss: 0.0163\n",
      "Epoch [70/400], Loss: 0.0169, Best Loss: 0.0163\n",
      "Epoch [80/400], Loss: 0.0163, Best Loss: 0.0159\n",
      "Epoch [90/400], Loss: 0.0157, Best Loss: 0.0157\n",
      "Epoch [100/400], Loss: 0.0157, Best Loss: 0.0157\n",
      "Epoch [110/400], Loss: 0.0158, Best Loss: 0.0157\n",
      "Epoch [120/400], Loss: 0.0156, Best Loss: 0.0156\n",
      "Epoch [130/400], Loss: 0.0158, Best Loss: 0.0152\n",
      "Epoch [140/400], Loss: 0.0153, Best Loss: 0.0152\n",
      "Epoch [150/400], Loss: 0.0160, Best Loss: 0.0152\n",
      "Epoch [160/400], Loss: 0.0156, Best Loss: 0.0152\n",
      "Epoch [170/400], Loss: 0.0156, Best Loss: 0.0152\n",
      "Epoch [180/400], Loss: 0.0157, Best Loss: 0.0152\n",
      "Epoch [190/400], Loss: 0.0154, Best Loss: 0.0151\n",
      "Epoch [200/400], Loss: 0.0155, Best Loss: 0.0150\n",
      "Epoch [210/400], Loss: 0.0161, Best Loss: 0.0149\n",
      "Epoch [220/400], Loss: 0.0153, Best Loss: 0.0145\n",
      "Epoch [230/400], Loss: 0.0154, Best Loss: 0.0145\n",
      "Epoch [240/400], Loss: 0.0144, Best Loss: 0.0144\n",
      "Epoch [250/400], Loss: 0.0143, Best Loss: 0.0143\n",
      "Epoch [260/400], Loss: 0.0147, Best Loss: 0.0142\n",
      "Epoch [270/400], Loss: 0.0148, Best Loss: 0.0142\n",
      "Epoch [280/400], Loss: 0.0144, Best Loss: 0.0142\n",
      "Epoch [290/400], Loss: 0.0144, Best Loss: 0.0142\n",
      "Epoch [300/400], Loss: 0.0141, Best Loss: 0.0141\n",
      "Epoch [310/400], Loss: 0.0139, Best Loss: 0.0139\n",
      "Epoch [320/400], Loss: 0.0151, Best Loss: 0.0139\n",
      "Epoch [330/400], Loss: 0.0145, Best Loss: 0.0139\n",
      "Epoch [340/400], Loss: 0.0142, Best Loss: 0.0138\n",
      "Epoch [350/400], Loss: 0.0135, Best Loss: 0.0135\n",
      "Epoch [360/400], Loss: 0.0142, Best Loss: 0.0135\n",
      "Epoch [370/400], Loss: 0.0140, Best Loss: 0.0135\n",
      "Epoch [380/400], Loss: 0.0142, Best Loss: 0.0135\n",
      "Epoch [390/400], Loss: 0.0140, Best Loss: 0.0135\n",
      "Epoch [400/400], Loss: 0.0141, Best Loss: 0.0135\n",
      "Average Sample Training Time: 6.452675991588168e-05 seconds\n",
      "Training Time: 7.000539779663086 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.6, shuffle=True)\n",
    "xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, test_size=0.2, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)\n",
    "xval = scaler.transform(xval)\n",
    "\n",
    "xtrain = torch.tensor(xtrain, dtype=torch.float32)\n",
    "xtest = torch.tensor(xtest, dtype=torch.float32)\n",
    "xval = torch.tensor(xval, dtype=torch.float32)\n",
    "\n",
    "ytrain = torch.tensor(ytrain.values, dtype=torch.float32)\n",
    "ytest = torch.tensor(ytest.values, dtype=torch.float32)\n",
    "yval = torch.tensor(yval.values, dtype=torch.float32)\n",
    "\n",
    "model = Model(X.shape[1], y.shape[1])\n",
    "start_time = time.time()\n",
    "model.train(xtrain, ytrain, xtest, ytest)\n",
    "end_time = time.time()\n",
    "print(f\"Training Time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.016092143952846527\n"
     ]
    }
   ],
   "source": [
    "model.model.eval()\n",
    "outputs = model.predict(xval)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "loss = loss_fn(outputs, yval)\n",
    "print(f\"Validation Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1420,  0.0615, -0.0186,  0.0187, -0.1558]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1467,  0.0661, -0.0300,  0.0279, -0.1352]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def predict(value):\n",
    "    value = scaler.transform([value])\n",
    "    value = torch.tensor(value, dtype=torch.float32).reshape(1, -1)\n",
    "    return model.predict(value)\n",
    "\n",
    "print(predict([0, 0, 0, 0, 0]))\n",
    "print(predict([0, 0, 0, 0, 1000]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
