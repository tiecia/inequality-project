{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"5L8LlfMsfB7n","executionInfo":{"status":"ok","timestamp":1732239032088,"user_tz":480,"elapsed":5909,"user":{"displayName":"Tyler Ciapala-Hazlerig","userId":"10162869139598719283"}}},"outputs":[],"source":["import pandas as pd\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n","\n","indicatorsDf = pd.read_excel('https://github.com/tiecia/inequality-project/raw/refs/heads/main/StateIndicatorsDatabase_2024.xlsx', sheet_name='Data')\n","\n","x_cols = ['necm_fundinggap_q1', 'necm_fundinggap_q2', 'necm_fundinggap_q3', 'necm_fundinggap_q4', 'necm_fundinggap_q5',\n","          'tchsalary25_30', 'tchsalary31_40', 'tchsalary41_50', 'tchsalary51_60',\n","          'predicted_tchph0_', 'predicted_tchph10_', 'predicted_tchph20_', 'predicted_tchph30_']\n","\n","y_cols = ['necm_outcomegap_q1', 'necm_outcomegap_q2', 'necm_outcomegap_q3', 'necm_outcomegap_q4', 'necm_outcomegap_q5']\n","\n","df = indicatorsDf[x_cols + y_cols]\n","\n","df.dropna(inplace=True)\n","\n","X = df[x_cols]\n","y = df[y_cols]\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ZUWfc27afB7o","executionInfo":{"status":"ok","timestamp":1732239985770,"user_tz":480,"elapsed":261,"user":{"displayName":"Tyler Ciapala-Hazlerig","userId":"10162869139598719283"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import time\n","import copy\n","\n","class Network(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(Network, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 64)\n","        self.fc2 = nn.Linear(64, 32)\n","        self.fc3 = nn.Linear(32, 16)\n","        self.fc4 = nn.Linear(16, output_size)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.1)\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc2(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","\n","class Model:\n","  def __init__(self, input_dims, output_dims):\n","    self.model = Network(input_dims, output_dims)\n","\n","  def train(self, xtrain, ytrain, xval, yval):\n","    loss_fn = nn.MSELoss(reduction=\"mean\")\n","    optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n","\n","    n_epochs = 400\n","    batch_size = 15\n","    batch_start = torch.arange(0, len(xtrain), batch_size)\n","\n","    best_loss = np.inf\n","    best_weights = None\n","\n","    print(f\"Training with {n_epochs} epochs and a batch size of {batch_size}\")\n","\n","    sample_times = []\n","\n","    for epoch in range(n_epochs):\n","      self.model.train()\n","\n","      for start in batch_start:\n","          # take a batch\n","          X_batch = xtrain[start:start+batch_size]\n","          y_batch = ytrain[start:start+batch_size]\n","\n","          start_time = time.time()\n","\n","          # forward pass\n","          outputs = self.model(X_batch)\n","          loss = loss_fn(outputs, y_batch)\n","          # backward pass\n","          optimizer.zero_grad()\n","          loss.backward()\n","          # update weights\n","          optimizer.step()\n","\n","          end_time = time.time()\n","          sample_times.append((end_time - start_time) / batch_size)\n","\n","      self.model.eval()\n","      outputs = self.model(xval)\n","      loss = loss_fn(outputs, yval)\n","      if loss < best_loss:\n","          best_loss = loss\n","          best_weights = copy.deepcopy(self.model.state_dict())\n","\n","      if (epoch+1) % 10 == 0:\n","        print('Epoch [{}/{}], Loss: {:.4f}, Best Loss: {:.4f}'.format(epoch+1, n_epochs, loss, best_loss))\n","\n","    print(f\"Average Sample Training Time: {np.mean(sample_times)} seconds\")\n","    self.model.load_state_dict(best_weights)\n","\n","  def predict(self, value):\n","    return self.model(value)"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_EDoUnR0fB7q","executionInfo":{"status":"ok","timestamp":1732242596756,"user_tz":480,"elapsed":9032,"user":{"displayName":"Tyler Ciapala-Hazlerig","userId":"10162869139598719283"}},"outputId":"6c4db25d-c231-4ba9-9a76-fd7ef5c4d6ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training with 400 epochs and a batch size of 15\n","Epoch [10/400], Loss: 0.0308, Best Loss: 0.0308\n","Epoch [20/400], Loss: 0.0266, Best Loss: 0.0266\n","Epoch [30/400], Loss: 0.0250, Best Loss: 0.0250\n","Epoch [40/400], Loss: 0.0244, Best Loss: 0.0244\n","Epoch [50/400], Loss: 0.0232, Best Loss: 0.0222\n","Epoch [60/400], Loss: 0.0239, Best Loss: 0.0215\n","Epoch [70/400], Loss: 0.0211, Best Loss: 0.0204\n","Epoch [80/400], Loss: 0.0215, Best Loss: 0.0194\n","Epoch [90/400], Loss: 0.0214, Best Loss: 0.0194\n","Epoch [100/400], Loss: 0.0202, Best Loss: 0.0190\n","Epoch [110/400], Loss: 0.0194, Best Loss: 0.0187\n","Epoch [120/400], Loss: 0.0204, Best Loss: 0.0187\n","Epoch [130/400], Loss: 0.0181, Best Loss: 0.0180\n","Epoch [140/400], Loss: 0.0194, Best Loss: 0.0171\n","Epoch [150/400], Loss: 0.0176, Best Loss: 0.0171\n","Epoch [160/400], Loss: 0.0179, Best Loss: 0.0171\n","Epoch [170/400], Loss: 0.0166, Best Loss: 0.0166\n","Epoch [180/400], Loss: 0.0162, Best Loss: 0.0162\n","Epoch [190/400], Loss: 0.0170, Best Loss: 0.0162\n","Epoch [200/400], Loss: 0.0158, Best Loss: 0.0155\n","Epoch [210/400], Loss: 0.0157, Best Loss: 0.0155\n","Epoch [220/400], Loss: 0.0167, Best Loss: 0.0155\n","Epoch [230/400], Loss: 0.0153, Best Loss: 0.0150\n","Epoch [240/400], Loss: 0.0160, Best Loss: 0.0150\n","Epoch [250/400], Loss: 0.0163, Best Loss: 0.0150\n","Epoch [260/400], Loss: 0.0169, Best Loss: 0.0150\n","Epoch [270/400], Loss: 0.0160, Best Loss: 0.0150\n","Epoch [280/400], Loss: 0.0146, Best Loss: 0.0146\n","Epoch [290/400], Loss: 0.0153, Best Loss: 0.0146\n","Epoch [300/400], Loss: 0.0152, Best Loss: 0.0146\n","Epoch [310/400], Loss: 0.0157, Best Loss: 0.0146\n","Epoch [320/400], Loss: 0.0156, Best Loss: 0.0146\n","Epoch [330/400], Loss: 0.0157, Best Loss: 0.0146\n","Epoch [340/400], Loss: 0.0151, Best Loss: 0.0146\n","Epoch [350/400], Loss: 0.0154, Best Loss: 0.0145\n","Epoch [360/400], Loss: 0.0156, Best Loss: 0.0145\n","Epoch [370/400], Loss: 0.0153, Best Loss: 0.0145\n","Epoch [380/400], Loss: 0.0149, Best Loss: 0.0145\n","Epoch [390/400], Loss: 0.0146, Best Loss: 0.0136\n","Epoch [400/400], Loss: 0.0153, Best Loss: 0.0136\n","Average Sample Training Time: 0.00011756114164988199 seconds\n","Training Time: 9.08253526687622 seconds\n"]}],"source":["from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","\n","xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.6, shuffle=True)\n","xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, test_size=0.2, shuffle=True)\n","\n","scaler = StandardScaler()\n","xtrain = scaler.fit_transform(xtrain)\n","xtest = scaler.transform(xtest)\n","xval = scaler.transform(xval)\n","\n","xtrain = torch.tensor(xtrain, dtype=torch.float32)\n","xtest = torch.tensor(xtest, dtype=torch.float32)\n","xval = torch.tensor(xval, dtype=torch.float32)\n","\n","ytrain = torch.tensor(ytrain.values, dtype=torch.float32)\n","ytest = torch.tensor(ytest.values, dtype=torch.float32)\n","yval = torch.tensor(yval.values, dtype=torch.float32)\n","\n","model = Model(X.shape[1], y.shape[1])\n","start_time = time.time()\n","model.train(xtrain, ytrain, xtest, ytest)\n","end_time = time.time()\n","print(f\"Training Time: {end_time - start_time} seconds\")"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkPQaCtNfB7s","executionInfo":{"status":"ok","timestamp":1732242605771,"user_tz":480,"elapsed":356,"user":{"displayName":"Tyler Ciapala-Hazlerig","userId":"10162869139598719283"}},"outputId":"71e30d3b-ff87-4523-9b85-0c238cc7ae99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.019542936235666275\n","Average Difference: 0.043055061250925064\n","Stdevs: 0.27105629444122314\n"]}],"source":["model.model.eval()\n","outputs = model.predict(xval).detach()\n","\n","loss_fn = nn.MSELoss(reduction=\"mean\")\n","loss = loss_fn(outputs, yval)\n","print(f\"Validation Loss: {loss}\")\n","\n","differences = []\n","for i in range(len(yval)):\n","  differences.append(yval[i] - outputs[i])\n","\n","mean = np.mean(differences)\n","actual_stdev = yval.std()\n","print(f\"Average Difference: {mean}\")\n","print(f\"Stdevs: {actual_stdev}\")"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZN4vBE_SfB7s","executionInfo":{"status":"ok","timestamp":1732242609460,"user_tz":480,"elapsed":221,"user":{"displayName":"Tyler Ciapala-Hazlerig","userId":"10162869139598719283"}},"outputId":"d3ca86c1-c1a8-4958-e2f2-2bdf44368c21"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3.3540, 0.9323, 0.7792, 2.1304, 2.4886]], grad_fn=<AddmmBackward0>)\n"]}],"source":["def predict(value):\n","    value = scaler.transform([value])\n","    value = torch.tensor(value, dtype=torch.float32).reshape(1, -1)\n","    return model.predict(value)\n","\n","# Funding gap (USD)\n","poverty_q1 = 0\n","poverty_q2 = 0\n","poverty_q3 = 0\n","poverty_q4 = 0\n","poverty_q5 = 1000\n","\n","teacher_salary = 50000\n","teacher_per_100_students = 60\n","\n","print(predict([poverty_q1, poverty_q2, poverty_q3, poverty_q4, poverty_q5,\n","               teacher_salary, teacher_salary, teacher_salary, teacher_salary,\n","               teacher_per_100_students, teacher_per_100_students, teacher_per_100_students, teacher_per_100_students]))"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}